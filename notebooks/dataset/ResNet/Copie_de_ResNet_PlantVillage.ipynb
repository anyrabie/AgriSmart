{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceType": "datasetVersion",
          "sourceId": 14841043,
          "datasetId": 9492136,
          "databundleVersionId": 15700176
        }
      ],
      "dockerImageVersionId": 31286,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Step 0: Import Kaggle dataset into Colab\n",
        "This cell downloads the PlantVillage dataset split (70/15/15) directly from Kaggle using `kagglehub`.  \n",
        "It ensures that the dataset is available in the Colab environment for training and testing.  \n",
        "⚠️ Note: Colab’s environment differs from Kaggle’s, so some libraries may not be preinstalled.\n"
      ],
      "metadata": {
        "id": "5sax4R3vpK7T"
      }
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "rabieoudghiri_plantvillage_split_70_15_15_path = kagglehub.dataset_download('rabieoudghiri/plantvillage-split-70-15-15')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CakQdnX8m9Cu",
        "outputId": "1bb8d494-17a5-4eb5-ca17-1f1e33dc0f42"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (1.0.0).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/rabieoudghiri/plantvillage-split-70-15-15?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 485M/485M [00:24<00:00, 20.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bIjzCwTnszS",
        "outputId": "d444cf98-c15a-4339-853d-e76ba6d137e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.12.19)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (26.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.1.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.78.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.46.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2026.1.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.5)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Import libraries and set random seed\n",
        "In this step, we import the necessary libraries for building and training our deep learning model.  \n",
        "We use TensorFlow/Keras for model creation, ResNet50 as the base architecture, and utility modules for preprocessing images.  \n",
        "We also set a random seed to ensure reproducibility — meaning that results will be consistent each time the notebook is run.\n"
      ],
      "metadata": {
        "id": "NIA0tN5bpUrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "\n",
        "# Set the seed for reproducibility\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-02-20T10:22:36.290139Z",
          "iopub.execute_input": "2026-02-20T10:22:36.291165Z",
          "iopub.status.idle": "2026-02-20T10:23:09.315531Z",
          "shell.execute_reply.started": "2026-02-20T10:22:36.291129Z",
          "shell.execute_reply": "2026-02-20T10:23:09.314311Z"
        },
        "id": "N914NRtZm9Cz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Define dataset directories\n",
        "We specify the paths to the training, validation, and test sets.  \n",
        "These directories contain the PlantVillage leaf images split into 70% training, 15% validation, and 15% test.  \n",
        "Keras will later use these paths to load images and generate batches for model training and evaluation.\n"
      ],
      "metadata": {
        "id": "d5qo6Nkgpc17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset directories\n",
        "train_dir = '/kaggle/input/plantvillage-split-70-15-15/plantvillage_split/train'\n",
        "val_dir = '/kaggle/input/plantvillage-split-70-15-15/plantvillage_split/valid'\n",
        "test_dir = '/kaggle/input/plantvillage-split-70-15-15/plantvillage_split/test'\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "ZRhFD4Awm9C0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Prepare data generators\n",
        "We redefine the dataset directories using the path downloaded from KaggleHub.  \n",
        "Then, we create `ImageDataGenerator` objects for training, validation, and testing.  \n",
        "These generators handle preprocessing (using ResNet50’s `preprocess_input`) and automatically load images from the dataset folders.  \n",
        "Finally, we build data loaders (`flow_from_directory`) that will feed batches of images into the model during training and evaluation.\n"
      ],
      "metadata": {
        "id": "tXAZHnKvpjps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "import os # Import the os module for path manipulation\n",
        "\n",
        "# Redefine dataset directories with the correct path obtained from kagglehub\n",
        "base_data_path = rabieoudghiri_plantvillage_split_70_15_15_path\n",
        "train_dir = os.path.join(base_data_path, 'plantvillage_split', 'train')\n",
        "val_dir = os.path.join(base_data_path, 'plantvillage_split', 'valid')\n",
        "test_dir = os.path.join(base_data_path, 'plantvillage_split', 'test')\n",
        "\n",
        "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(224,224), batch_size=32, class_mode='categorical')\n",
        "val_generator = val_datagen.flow_from_directory(val_dir, target_size=(224,224), batch_size=32, class_mode='categorical')\n",
        "test_generator = test_datagen.flow_from_directory(test_dir, target_size=(224,224), batch_size=32, class_mode='categorical')"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaEX4bJYm9C1",
        "outputId": "b0452056-472a-4292-b915-b5464b93f7a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 37997 images belonging to 38 classes.\n",
            "Found 8129 images belonging to 38 classes.\n",
            "Found 8180 images belonging to 38 classes.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Build the transfer learning model\n",
        "We use ResNet50 (pretrained on ImageNet) as the base model for feature extraction.  \n",
        "The top (fully connected) layers are removed, and we freeze the base layers so they are not retrained.  \n",
        "On top of ResNet50, we add custom layers:\n",
        "- Global Average Pooling to reduce feature maps into a single vector.\n",
        "- Dense layers (128 and 64 units) with ReLU activation for learning task-specific features.\n",
        "- Final Dense layer with softmax activation to classify images into the PlantVillage disease categories.\n"
      ],
      "metadata": {
        "id": "ndLE0C88pqPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ResNet50 base model\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
        "base_model.trainable = False  # freeze base layers\n",
        "\n",
        "# Add custom layers\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "\n",
        "# Build model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6KtViLpm9C1",
        "outputId": "15de3b20-3a0f-431d-a926-8366bad35c30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Compile the model\n",
        "We compile the model by specifying:\n",
        "- **Optimizer:** Adam with a learning rate of 0.0001, which balances speed and stability during training.\n",
        "- **Loss function:** Categorical crossentropy, suitable for multi-class classification problems.\n",
        "- **Metrics:** Accuracy, to monitor how well the model is performing during training and evaluation.\n"
      ],
      "metadata": {
        "id": "vgQMuW7Jpvey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "QEC9Vjetm9C2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6: Train the model\n",
        "We train the model using the training data generator for 20 epochs.  \n",
        "During training, the model learns to classify leaf images into disease categories.  \n",
        "We also provide the validation generator so the model’s performance can be monitored on unseen data after each epoch.  \n",
        "The training history (loss and accuracy values) will be stored in the `history` object for later visualization.\n"
      ],
      "metadata": {
        "id": "-y6WpLKWpz7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator,\n",
        "                    epochs=20,\n",
        "                    validation_data=val_generator)\n"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVSNKNYFm9C2",
        "outputId": "4e4c6f72-3954-4678-ec5a-69e3d3a7c43e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 111ms/step - accuracy: 0.5584 - loss: 1.8523 - val_accuracy: 0.8945 - val_loss: 0.4256\n",
            "Epoch 2/20\n",
            "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 106ms/step - accuracy: 0.9132 - loss: 0.3468 - val_accuracy: 0.9363 - val_loss: 0.2389\n",
            "Epoch 3/20\n",
            "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 105ms/step - accuracy: 0.9466 - loss: 0.2042 - val_accuracy: 0.9519 - val_loss: 0.1820\n",
            "Epoch 4/20\n",
            "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 106ms/step - accuracy: 0.9626 - loss: 0.1471 - val_accuracy: 0.9546 - val_loss: 0.1570\n",
            "Epoch 5/20\n",
            "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 106ms/step - accuracy: 0.9715 - loss: 0.1131 - val_accuracy: 0.9592 - val_loss: 0.1410\n",
            "Epoch 6/20\n",
            "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 106ms/step - accuracy: 0.9767 - loss: 0.0909 - val_accuracy: 0.9612 - val_loss: 0.1296\n",
            "Epoch 7/20\n",
            "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 106ms/step - accuracy: 0.9794 - loss: 0.0777 - val_accuracy: 0.9675 - val_loss: 0.1061\n",
            "Epoch 8/20\n",
            "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 105ms/step - accuracy: 0.9830 - loss: 0.0675 - val_accuracy: 0.9696 - val_loss: 0.1014\n",
            "Epoch 9/20\n",
            "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 106ms/step - accuracy: 0.9874 - loss: 0.0543 - val_accuracy: 0.9707 - val_loss: 0.0992\n",
            "Epoch 10/20\n",
            "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 105ms/step - accuracy: 0.9896 - loss: 0.0474 - val_accuracy: 0.9710 - val_loss: 0.0968\n",
            "Epoch 11/20\n",
            "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 106ms/step - accuracy: 0.9896 - loss: 0.0433 - val_accuracy: 0.9722 - val_loss: 0.0916\n",
            "Epoch 12/20\n",
            "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 106ms/step - accuracy: 0.9922 - loss: 0.0358 - val_accuracy: 0.9750 - val_loss: 0.0825\n",
            "Epoch 13/20\n",
            "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 106ms/step - accuracy: 0.9937 - loss: 0.0314 - val_accuracy: 0.9708 - val_loss: 0.0922\n",
            "Epoch 14/20\n",
            "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 106ms/step - accuracy: 0.9943 - loss: 0.0273 - val_accuracy: 0.9761 - val_loss: 0.0821\n",
            "Epoch 15/20\n",
            "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 106ms/step - accuracy: 0.9950 - loss: 0.0239 - val_accuracy: 0.9752 - val_loss: 0.0829\n",
            "Epoch 16/20\n",
            "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 106ms/step - accuracy: 0.9968 - loss: 0.0200 - val_accuracy: 0.9750 - val_loss: 0.0885\n",
            "Epoch 17/20\n",
            "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 107ms/step - accuracy: 0.9976 - loss: 0.0178 - val_accuracy: 0.9766 - val_loss: 0.0837\n",
            "Epoch 18/20\n",
            "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 106ms/step - accuracy: 0.9980 - loss: 0.0147 - val_accuracy: 0.9779 - val_loss: 0.0784\n",
            "Epoch 19/20\n",
            "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 106ms/step - accuracy: 0.9970 - loss: 0.0146 - val_accuracy: 0.9750 - val_loss: 0.0819\n",
            "Epoch 20/20\n",
            "\u001b[1m1188/1188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 106ms/step - accuracy: 0.9988 - loss: 0.0110 - val_accuracy: 0.9742 - val_loss: 0.0825\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 7: Evaluate the model on the test set\n",
        "After training, we evaluate the model using the test dataset.  \n",
        "This step measures how well the model generalizes to completely unseen data.  \n",
        "We calculate the test loss and test accuracy, then print the accuracy score.\n"
      ],
      "metadata": {
        "id": "F-JH7fdJp5Ki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Hq0Efg9m9C2",
        "outputId": "430d20c1-4e36-486a-ebf0-75c24f175dd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m256/256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 103ms/step - accuracy: 0.9780 - loss: 0.0794\n",
            "Test accuracy: 0.9741\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/plant_disease_resnet50.h5')\n"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUXqJ_VXm9C3",
        "outputId": "c1735137-9291-4d42-9c7b-803fe48a9de9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Save model to Google Drive\n",
        "model.save('/content/drive/MyDrive/plant_disease_resnet50.h5')\n"
      ],
      "metadata": {
        "id": "TIuznyQV1IoW",
        "outputId": "1249343a-086b-4003-c2df-f6ea89fc3ee6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xgOrUe6u2eSe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}